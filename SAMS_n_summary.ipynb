{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code is attempting to count the numbers of participants\n",
    "## who have data for each SAMS modality at baseline based on a \n",
    "## redcap reports from both the SAMS contact database as well as the \n",
    "## de-identified SAMS database\n",
    "\n",
    "## Note: at the time of this code (Sept 2020) not all participants \n",
    "## have wave 1 7T info in redcap, so this data needs to be obtained\n",
    "## from header information on Oak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "import glob\n",
    "import string\n",
    "import statistics\n",
    "from os.path import exists\n",
    "from pydicom import dcmread\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for the W2 7T session\n",
    "w2_7t_session = pd.DataFrame()\n",
    "curr_path = '/Users/madisonhunt/Desktop/W2_7T_SessionInfo.csv'\n",
    "w2_7t_session = pd.read_csv(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pidn</th>\n",
       "      <th>fse_ses1</th>\n",
       "      <th>ufse_ses1</th>\n",
       "      <th>wmn_ses1</th>\n",
       "      <th>mtrage_ses1</th>\n",
       "      <th>flair_ses1</th>\n",
       "      <th>csfn_ses1</th>\n",
       "      <th>mepi_ses1</th>\n",
       "      <th>gmn_ses1</th>\n",
       "      <th>qti_ses1</th>\n",
       "      <th>fse_ses2</th>\n",
       "      <th>ufse_ses2</th>\n",
       "      <th>wmn_ses2</th>\n",
       "      <th>mtrage_ses2</th>\n",
       "      <th>flair_ses2</th>\n",
       "      <th>csfn_ses2</th>\n",
       "      <th>mepi_ses2</th>\n",
       "      <th>gmn_ses2</th>\n",
       "      <th>qti_ses2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pidn  fse_ses1  ufse_ses1  wmn_ses1  mtrage_ses1  flair_ses1  csfn_ses1  \\\n",
       "0   203         1          0         1            1           0          1   \n",
       "1   301         1          1         0            0           0          0   \n",
       "2   303         1          0         1            1           0          1   \n",
       "3   457         1          0         1            1           0          1   \n",
       "4   472         1          0         1            1           0          1   \n",
       "\n",
       "   mepi_ses1  gmn_ses1  qti_ses1  fse_ses2  ufse_ses2  wmn_ses2  mtrage_ses2  \\\n",
       "0          1         1         1         0          0         0            0   \n",
       "1          0         0         0         0          0         0            0   \n",
       "2          1         1         1         0          0         0            1   \n",
       "3          1         1         1         0          0         0            1   \n",
       "4          1         1         1         0          0         0            0   \n",
       "\n",
       "   flair_ses2  csfn_ses2  mepi_ses2  gmn_ses2  qti_ses2  \n",
       "0           0          0          0         0         0  \n",
       "1           0          0          0         0         0  \n",
       "2           0          1          0         1         1  \n",
       "3           0          1          0         1         1  \n",
       "4           0          0          0         0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_7t_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for the W1 Visit Summary\n",
    "w1_visit_summ = pd.DataFrame\n",
    "curr_path = '/Users/madisonhunt/Desktop/W1_Visit_Summary.csv'\n",
    "w1_visit_summ = pd.read_csv(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pidn</th>\n",
       "      <th>w1_blood</th>\n",
       "      <th>w1_csf</th>\n",
       "      <th>w1_cni</th>\n",
       "      <th>w1_7t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pidn  w1_blood  w1_csf  w1_cni  w1_7t\n",
       "0   203         1       1     0.0      1\n",
       "1   301         1       1     1.0      1\n",
       "2   303         1       1     1.0      1\n",
       "3   405         1       1     1.0      0\n",
       "4   415         1       1     0.0      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_visit_summ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for the W1 7T session that is entered in redcap. \n",
    "#Later we will check the files that are not documented in redcap\n",
    "\n",
    "w1_7t_session = pd.DataFrame\n",
    "curr_path = '/Users/madisonhunt/Desktop/w1_7t_session.csv'\n",
    "w1_7t_session = pd.read_csv(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in data for the W2 visit summary\n",
    "\n",
    "w2_visit_summ = pd.DataFrame()\n",
    "curr_path = '/Users/madisonhunt/Desktop/w2_visit_summary.csv'\n",
    "w2_visit_summ= pd.read_csv(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in participant visit dates (will be used later to determine \n",
    "#if data was collected within the 2 year window)\n",
    "\n",
    "visit_dates = pd.DataFrame()\n",
    "curr_path = '/Users/madisonhunt/Desktop/SAMS_visit_dates.csv'\n",
    "visit_dates = pd.read_csv(curr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pidn      wave ab_group ptau_group   lp_date\n",
      "0     203     Wave2      ab-        NaN       NaN\n",
      "1     301  Baseline      ab-         T-       NaN\n",
      "2     303  Baseline      ab-         T-       NaN\n",
      "3     405  Baseline      ab+         T+       NaN\n",
      "4     415  Baseline      ab-         T+       NaN\n",
      "5     423  Baseline      ab-         T+       NaN\n",
      "6     447  Baseline      ab+         T-       NaN\n",
      "7     449  Baseline      ab-         T+       NaN\n",
      "8     456  Baseline      ab-         T+       NaN\n",
      "9     457  Baseline      ab-         T-   9/10/19\n",
      "10    468  Baseline      ab-         T-       NaN\n",
      "11    470  Baseline      ab-         T-       NaN\n",
      "12    472     Wave2      ab-        NaN   12/3/19\n",
      "13    474  Baseline      ab+         T+       NaN\n",
      "14    475  Baseline      ab-         T-       NaN\n",
      "15    476     Wave2      ab-        NaN   9/17/19\n",
      "16    477  Baseline      ab-         T-       NaN\n",
      "17    478  Baseline      ab-         T-       NaN\n",
      "18    479  Baseline      ab+         T-       NaN\n",
      "19    481  Baseline      ab-         T-       NaN\n",
      "20    482  Baseline      ab-         T-       NaN\n",
      "21    489  Baseline      ab-         T-       NaN\n",
      "22    500  Baseline      ab-         T+  12/11/19\n",
      "23    504  Baseline      ab-         T-   7/31/19\n",
      "24    507     Wave2      ab-        NaN   7/10/19\n",
      "25    508  Baseline      ab-         T-       NaN\n",
      "26    528  Baseline      ab+         T+       NaN\n",
      "27    531  Baseline      ab+         T+       NaN\n",
      "28    532     Wave2      ab-        NaN       NaN\n",
      "29    534  Baseline      ab-         T-   9/10/19\n",
      "..    ...       ...      ...        ...       ...\n",
      "148  1067  Baseline      ab-         T-       NaN\n",
      "149  1077  Baseline      ab-         T-       NaN\n",
      "150  1080  Baseline      ab-         T-       NaN\n",
      "151  1083  Baseline      ab+         T+       NaN\n",
      "152  1095  Baseline      ab+         T-       NaN\n",
      "153  1097  Baseline      ab-        NaN   8/28/19\n",
      "154  1099  Baseline      ab+         T+       NaN\n",
      "155  1101  Baseline      ab-         T-       NaN\n",
      "156  1104  Baseline      ab-        NaN   10/3/19\n",
      "157  1116  Baseline      ab-         T-       NaN\n",
      "158  1119  Baseline      ab-        NaN    9/4/19\n",
      "159  1128  Baseline      ab+        NaN    9/3/19\n",
      "160  1135  Baseline      ab-        NaN    9/4/19\n",
      "161  1136  Baseline      ab-        NaN   10/8/19\n",
      "162  1137  Baseline      ab-        NaN   10/1/19\n",
      "163  1141  Baseline      ab+        NaN    9/4/19\n",
      "164  1163  Baseline      ab+         T+       NaN\n",
      "165  1183  Baseline      ab+        NaN   10/2/19\n",
      "166  1184  Baseline      ab+        NaN   9/25/19\n",
      "167  1185  Baseline      ab+         T+       NaN\n",
      "168  1190  Baseline      ab-         T-       NaN\n",
      "169  1192  Baseline      ab-         T-       NaN\n",
      "170  1193  Baseline      ab+         T-       NaN\n",
      "171  1195  Baseline      ab-        NaN   1/23/20\n",
      "172  1196  Baseline      ab-        NaN    2/5/20\n",
      "173  1201  Baseline      ab+         T+       NaN\n",
      "174  1227  Baseline      ab-         T-       NaN\n",
      "175  1230  Baseline      ab-         T-       NaN\n",
      "176  1231  Baseline      ab-         T+       NaN\n",
      "177  1234  Baseline      ab-        NaN  12/19/19\n",
      "\n",
      "[178 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PET_data = pd.DataFrame()\n",
    "curr_path = '/Users/madisonhunt/Desktop/SAMS_bio_status.csv'\n",
    "PET_data = pd.read_csv(curr_path)\n",
    "\n",
    "print(PET_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "ab_pos = len(PET_data[PET_data['ab_group'] == 'ab+'])\n",
    "tau_pos = len(PET_data[PET_data['ptau_group'] == 'T+'])\n",
    "both_pos = len(PET_data[(PET_data['ab_group'] == 'ab+') & (PET_data['ptau_group'] == 'T+')])\n",
    "\n",
    "total_pos = ab_pos + tau_pos - both_pos\n",
    "\n",
    "print(ab_pos)\n",
    "print(total_pos)\n",
    "\n",
    "##June 25, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29      9/10/19\n",
      "30          NaN\n",
      "31          NaN\n",
      "32          NaN\n",
      "33          NaN\n",
      "34          NaN\n",
      "35          NaN\n",
      "36          NaN\n",
      "37          NaN\n",
      "38          NaN\n",
      "39      6/25/19\n",
      "40          NaN\n",
      "41          NaN\n",
      "42     10/15/19\n",
      "43          NaN\n",
      "44          NaN\n",
      "45      1/30/20\n",
      "46          NaN\n",
      "47          NaN\n",
      "48          NaN\n",
      "49          NaN\n",
      "50          NaN\n",
      "51          NaN\n",
      "52          NaN\n",
      "53          NaN\n",
      "54          NaN\n",
      "55     11/21/19\n",
      "56          NaN\n",
      "57     11/12/19\n",
      "58          NaN\n",
      "         ...   \n",
      "119         NaN\n",
      "120         NaN\n",
      "121         NaN\n",
      "122         NaN\n",
      "123         NaN\n",
      "124         NaN\n",
      "125         NaN\n",
      "126         NaN\n",
      "127         NaN\n",
      "128         NaN\n",
      "129         NaN\n",
      "130         NaN\n",
      "131         NaN\n",
      "132         NaN\n",
      "133         NaN\n",
      "134         NaN\n",
      "135         NaN\n",
      "136         NaN\n",
      "137         NaN\n",
      "138         NaN\n",
      "139         NaN\n",
      "140         NaN\n",
      "141         NaN\n",
      "142         NaN\n",
      "143         NaN\n",
      "144         NaN\n",
      "145         NaN\n",
      "146         NaN\n",
      "147         NaN\n",
      "148         NaN\n",
      "Name: lp_date, Length: 120, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(PET_data.loc[29:148,'lp_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame for a summary of the available data \n",
    "# that was collected within the last two years\n",
    "avail_data_summ = pd.DataFrame()\n",
    "\n",
    "#add in all the pidns \n",
    "avail_data_summ['pidn'] = w1_visit_summ['pidn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       203\n",
      "1       301\n",
      "2       303\n",
      "3       405\n",
      "4       415\n",
      "5       416\n",
      "6       423\n",
      "7       447\n",
      "8       448\n",
      "9       449\n",
      "10      456\n",
      "11      457\n",
      "12      460\n",
      "13      463\n",
      "14      468\n",
      "15      470\n",
      "16      472\n",
      "17      474\n",
      "18      475\n",
      "19      476\n",
      "20      477\n",
      "21      478\n",
      "22      479\n",
      "23      481\n",
      "24      482\n",
      "25      488\n",
      "26      489\n",
      "27      500\n",
      "28      504\n",
      "29      507\n",
      "       ... \n",
      "187    1083\n",
      "188    1094\n",
      "189    1095\n",
      "190    1097\n",
      "191    1099\n",
      "192    1101\n",
      "193    1104\n",
      "194    1116\n",
      "195    1119\n",
      "196    1128\n",
      "197    1135\n",
      "198    1136\n",
      "199    1137\n",
      "200    1138\n",
      "201    1141\n",
      "202    1142\n",
      "203    1163\n",
      "204    1183\n",
      "205    1184\n",
      "206    1185\n",
      "207    1190\n",
      "208    1192\n",
      "209    1193\n",
      "210    1195\n",
      "211    1196\n",
      "212    1201\n",
      "213    1227\n",
      "214    1230\n",
      "215    1231\n",
      "216    1234\n",
      "Name: pidn, Length: 217, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(avail_data_summ['pidn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatenate the data into one data frame\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(w2_visit_summ, on = 'pidn', how='left')\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(w1_visit_summ, on = 'pidn', how='left')\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(w1_7t_session, on='pidn', how='left')\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(w2_7t_session, on = 'pidn', how='left')\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(PET_data, on = 'pidn', how='left')\n",
    "\n",
    "avail_data_summ = avail_data_summ.merge(visit_dates, on = 'pidn', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pidn  w2_blood  w2_csf  w2_7T  w1_blood  w1_csf  w1_cni  w1_7t  w1_fse  \\\n",
      "0     203       1.0     1.0    1.0         1       1     0.0      1       0   \n",
      "1     301       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "2     303       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "3     405       NaN     NaN    NaN         1       1     1.0      0       0   \n",
      "4     415       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "5     416       NaN     NaN    NaN         1       0     NaN      0       0   \n",
      "6     423       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "7     447       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "8     448       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "9     449       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "10    456       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "11    457       1.0     0.0    1.0         1       1     1.0      1       0   \n",
      "12    460       NaN     NaN    NaN         1       0     NaN      0       0   \n",
      "13    463       NaN     NaN    NaN         1       0     0.0      0       0   \n",
      "14    468       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "15    470       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "16    472       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "17    474       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "18    475       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "19    476       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "20    477       1.0     0.0    1.0         1       1     1.0      1       0   \n",
      "21    478       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "22    479       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "23    481       1.0     1.0    0.0         1       1     1.0      0       0   \n",
      "24    482       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "25    488       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "26    489       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "27    500       1.0     0.0    1.0         1       1     0.0      1       0   \n",
      "28    504       1.0     0.0    1.0         1       1     0.0      1       0   \n",
      "29    507       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "..    ...       ...     ...    ...       ...     ...     ...    ...     ...   \n",
      "187  1083       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "188  1094       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "189  1095       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "190  1097       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "191  1099       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "192  1101       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "193  1104       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "194  1116       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "195  1119       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "196  1128       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "197  1135       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "198  1136       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "199  1137       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "200  1138       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "201  1141       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "202  1142       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "203  1163       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "204  1183       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "205  1184       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "206  1185       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "207  1190       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "208  1192       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "209  1193       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "210  1195       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "211  1196       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "212  1201       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "213  1227       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "214  1230       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "215  1231       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "216  1234       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "\n",
      "     w1_ufse     ...      qti_ses2      wave  ab_group  ptau_group   lp_date  \\\n",
      "0          0     ...           0.0     Wave2       ab-         NaN       NaN   \n",
      "1          0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "2          0     ...           1.0  Baseline       ab-          T-       NaN   \n",
      "3          0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "4          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "5          0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "6          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "7          0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "8          0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "9          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "10         0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "11         0     ...           1.0  Baseline       ab-          T-   9/10/19   \n",
      "12         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "13         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "14         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "15         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "16         0     ...           0.0     Wave2       ab-         NaN   12/3/19   \n",
      "17         0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "18         0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "19         0     ...           0.0     Wave2       ab-         NaN   9/17/19   \n",
      "20         0     ...           1.0  Baseline       ab-          T-       NaN   \n",
      "21         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "22         0     ...           1.0  Baseline       ab+          T-       NaN   \n",
      "23         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "24         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "25         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "26         0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "27         0     ...           1.0  Baseline       ab-          T+  12/11/19   \n",
      "28         0     ...           1.0  Baseline       ab-          T-   7/31/19   \n",
      "29         0     ...           0.0     Wave2       ab-         NaN   7/10/19   \n",
      "..       ...     ...           ...       ...       ...         ...       ...   \n",
      "187        1     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "188        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "189        0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "190        1     ...           NaN  Baseline       ab-         NaN   8/28/19   \n",
      "191        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "192        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "193        0     ...           NaN  Baseline       ab-         NaN   10/3/19   \n",
      "194        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "195        0     ...           NaN  Baseline       ab-         NaN    9/4/19   \n",
      "196        0     ...           NaN  Baseline       ab+         NaN    9/3/19   \n",
      "197        0     ...           NaN  Baseline       ab-         NaN    9/4/19   \n",
      "198        0     ...           NaN  Baseline       ab-         NaN   10/8/19   \n",
      "199        0     ...           NaN  Baseline       ab-         NaN   10/1/19   \n",
      "200        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "201        1     ...           NaN  Baseline       ab+         NaN    9/4/19   \n",
      "202        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "203        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "204        0     ...           NaN  Baseline       ab+         NaN   10/2/19   \n",
      "205        0     ...           NaN  Baseline       ab+         NaN   9/25/19   \n",
      "206        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "207        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "208        1     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "209        0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "210        0     ...           NaN  Baseline       ab-         NaN   1/23/20   \n",
      "211        0     ...           NaN  Baseline       ab-         NaN    2/5/20   \n",
      "212        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "213        1     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "214        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "215        1     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "216        0     ...           NaN  Baseline       ab-         NaN  12/19/19   \n",
      "\n",
      "     intake_date_w1  cni_w1_date  lp_w1_date  intake_date_w2  lp_w2_date  \n",
      "0        2014-10-16   2014-08-22  2014-10-09      2018-12-10  2019-03-05  \n",
      "1        2014-10-09   2015-02-19  2014-10-09      2018-10-24  2019-01-23  \n",
      "2        2015-02-17   2015-02-17  2014-11-13      2019-02-12  2019-02-13  \n",
      "3        2014-07-08   2014-08-20  2014-07-08             NaN         NaN  \n",
      "4        2014-09-29   2014-11-24  2014-09-18             NaN         NaN  \n",
      "5        2014-08-26   2014-08-29         NaN             NaN         NaN  \n",
      "6        2014-09-23   2014-11-21  2014-11-18             NaN         NaN  \n",
      "7        2015-01-08          NaN  2015-01-13             NaN         NaN  \n",
      "8        2015-01-08   2015-01-08  2015-01-13             NaN         NaN  \n",
      "9        2014-12-10   2015-03-12  2015-03-05             NaN         NaN  \n",
      "10       2015-04-07   2015-04-02  2015-04-07             NaN         NaN  \n",
      "11       2015-03-17   2015-03-17  2015-03-23      2019-03-04  2019-03-18  \n",
      "12       2015-01-27          NaN         NaN             NaN         NaN  \n",
      "13       2015-02-10   2015-02-10         NaN             NaN         NaN  \n",
      "14       2015-03-10   2015-03-10  2015-03-18             NaN         NaN  \n",
      "15       2015-07-07   2015-07-07  2015-09-15             NaN         NaN  \n",
      "16       2015-03-24   2015-03-24  2015-04-06      2019-08-26  2019-10-22  \n",
      "17       2015-03-12   2015-03-12  2015-03-30             NaN         NaN  \n",
      "18       2015-02-24   2015-02-24  2015-03-04      2018-11-28  2019-03-06  \n",
      "19       2015-08-12   2015-08-12  2015-09-21      2019-08-12  2019-08-28  \n",
      "20       2016-02-16   2016-03-03  2016-04-11      2019-12-04         NaN  \n",
      "21       2015-09-30   2015-12-08  2015-10-14             NaN         NaN  \n",
      "22       2015-11-10   2015-12-01  2015-12-02      2019-05-16  2019-06-25  \n",
      "23       2015-03-11   2015-03-03  2015-03-24      2018-10-25  2019-01-15  \n",
      "24       2015-06-16   2015-06-16  2015-07-01             NaN         NaN  \n",
      "25       2015-02-12   2015-02-12  2015-02-18             NaN         NaN  \n",
      "26       2015-03-26   2015-03-26  2015-04-01      2018-11-01  2019-02-27  \n",
      "27       2015-10-13   2015-11-19  2015-12-16      2019-10-31         NaN  \n",
      "28       2015-04-16   2015-04-16  2015-05-06      2019-05-06  2019-05-07  \n",
      "29       2015-04-30   2015-04-30  2015-05-11      2019-02-26         NaN  \n",
      "..              ...          ...         ...             ...         ...  \n",
      "187      2018-08-21   2018-10-25  2018-12-04             NaN         NaN  \n",
      "188      2018-09-20   2018-11-19  2018-11-29             NaN         NaN  \n",
      "189      2018-10-04   2018-11-05  2018-12-05             NaN         NaN  \n",
      "190      2018-11-21   2019-01-31  2019-02-20             NaN         NaN  \n",
      "191      2018-10-22   2018-12-12  2019-01-29             NaN         NaN  \n",
      "192      2018-11-12   2019-01-21  2019-03-27             NaN         NaN  \n",
      "193      2018-10-18   2018-12-10  2018-12-11             NaN         NaN  \n",
      "194      2018-11-19   2018-12-18  2019-01-22             NaN         NaN  \n",
      "195      2019-02-19   2019-04-25  2019-04-03             NaN         NaN  \n",
      "196      2019-01-09   2019-02-11  2019-03-27             NaN         NaN  \n",
      "197      2019-01-14   2019-03-07  2019-03-20             NaN         NaN  \n",
      "198      2019-01-17   2019-02-26  2019-03-19             NaN         NaN  \n",
      "199      2019-02-11   2019-07-09  2019-04-09             NaN         NaN  \n",
      "200      2019-02-06   2019-04-30  2019-04-09             NaN         NaN  \n",
      "201      2019-02-04   2019-03-14  2019-03-20             NaN         NaN  \n",
      "202      2019-02-07   2019-03-28  2019-04-03             NaN         NaN  \n",
      "203      2019-03-07   2019-04-11  2019-07-02             NaN         NaN  \n",
      "204      2019-04-11   2019-06-11  2019-07-24             NaN         NaN  \n",
      "205      2019-04-16   2019-06-03  2019-07-23             NaN         NaN  \n",
      "206      2019-04-15   2019-05-09  2019-06-18             NaN         NaN  \n",
      "207      2019-06-06   2019-08-05  2019-10-10             NaN         NaN  \n",
      "208      2019-05-23   2019-08-01  2019-11-07             NaN         NaN  \n",
      "209      2019-05-20   2019-06-24  2019-09-18             NaN         NaN  \n",
      "210      2019-05-15   2019-08-12  2019-07-02             NaN         NaN  \n",
      "211      2019-07-30   2019-09-23  2019-10-15             NaN         NaN  \n",
      "212      2019-07-17   2019-09-30  2019-11-06             NaN         NaN  \n",
      "213      2019-09-10   2019-11-18  2020-01-30             NaN         NaN  \n",
      "214      2019-10-08   2019-11-04  2019-11-22             NaN         NaN  \n",
      "215      2019-09-09   2019-10-31  2020-01-23             NaN         NaN  \n",
      "216      2019-10-21   2019-12-09  2019-12-05             NaN         NaN  \n",
      "\n",
      "[217 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "## check that the data frame looks like we expect it to\n",
    "print(avail_data_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if a participant doesnt have an FSE recorded in redcap, check to see if they have a file on oak\n",
    "## this is due to an error that was made at the beginning of the study with documenting data collection\n",
    "\n",
    "#set current path to Oak folder\n",
    "curr_path = '/Users/madisonhunt/Desktop/Oak/7T_Data'\n",
    "\n",
    "## loop through the data that does not exist on redcap\n",
    "# used fse to determine because all participants should have an fse if they completed a scan\n",
    "for pid in avail_data_summ[avail_data_summ['w1_fse']==0]['pidn']:\n",
    "    #find all of the folders in the current participants path\n",
    "    pt_path = glob.glob(curr_path + '/0' + str(pid) + '_****/00*')\n",
    "    #set iterator \"folder\" to zero\n",
    "    folder = 0\n",
    "    #for the folders in the participant's data\n",
    "    for n in pt_path:\n",
    "        #calculate the number of files in each folder, this is a cheat way to determine which scan \n",
    "        #it is without looking at header information\n",
    "        num_files = len([f for f in os.listdir(pt_path[folder])])\n",
    "        # if the folder has 16 files, it is either an fse or an ungated fse. for the purpose of this\n",
    "        #code, we don't care which it is, so mark that they have an fse at w1\n",
    "        if num_files ==16:\n",
    "            avail_data_summ.loc[(avail_data_summ['pidn']==pid), 'w1_fse'] = 1\n",
    "        # if the folder has 46 files, it is the localizer and we do not care about this scan, so move on\n",
    "        elif num_files == 46:\n",
    "            continue\n",
    "        # if the folder has 216 files it a flair. mark that the participant has this scan    \n",
    "        elif num_files == 216:\n",
    "             avail_data_summ.loc[(avail_data_summ['pidn']==pid), 'w1_flair'] = 1\n",
    "        #if the folder has 316 files, mark that the participant has a cube\n",
    "        elif num_files == 312: \n",
    "             avail_data_summ.loc[(avail_data_summ['pidn']==pid), 'w1_cube'] = 1\n",
    "        # if the folder has 440 files, mark that the participant has a wmnMPRAGE\n",
    "        elif num_files == 440: \n",
    "             avail_data_summ.loc[(avail_data_summ['pidn']==pid), 'w1_wmnmprage'] = 1\n",
    "        # if the folder has another number of files, mark that there is an error so we can \n",
    "        # manually check what scan it is (first time run --> there are only 3 errors, so its not difficult to\n",
    "        # manually check)\n",
    "        else:\n",
    "            print('error on folder' + pt_path[folder])\n",
    "        ## increase the folder to re-loop\n",
    "        folder+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pidn</th>\n",
       "      <th>w2_blood</th>\n",
       "      <th>w2_csf</th>\n",
       "      <th>w2_7T</th>\n",
       "      <th>w1_blood</th>\n",
       "      <th>w1_csf</th>\n",
       "      <th>w1_cni</th>\n",
       "      <th>w1_7t</th>\n",
       "      <th>w1_fse</th>\n",
       "      <th>w1_ufse</th>\n",
       "      <th>...</th>\n",
       "      <th>qti_ses2</th>\n",
       "      <th>wave</th>\n",
       "      <th>ab_group</th>\n",
       "      <th>ptau_group</th>\n",
       "      <th>lp_date</th>\n",
       "      <th>intake_date_w1</th>\n",
       "      <th>cni_w1_date</th>\n",
       "      <th>lp_w1_date</th>\n",
       "      <th>intake_date_w2</th>\n",
       "      <th>lp_w2_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wave2</td>\n",
       "      <td>ab-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-16</td>\n",
       "      <td>2014-08-22</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>2019-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "      <td>T-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>2019-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "      <td>T-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>2015-02-17</td>\n",
       "      <td>2014-11-13</td>\n",
       "      <td>2019-02-12</td>\n",
       "      <td>2019-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab+</td>\n",
       "      <td>T+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-08</td>\n",
       "      <td>2014-08-20</td>\n",
       "      <td>2014-07-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "      <td>T+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pidn  w2_blood  w2_csf  w2_7T  w1_blood  w1_csf  w1_cni  w1_7t  w1_fse  \\\n",
       "0   203       1.0     1.0    1.0         1       1     0.0      1       0   \n",
       "1   301       1.0     1.0    1.0         1       1     1.0      1       0   \n",
       "2   303       1.0     1.0    1.0         1       1     1.0      1       0   \n",
       "3   405       NaN     NaN    NaN         1       1     1.0      0       0   \n",
       "4   415       NaN     NaN    NaN         1       1     0.0      1       0   \n",
       "\n",
       "   w1_ufse     ...      qti_ses2      wave  ab_group  ptau_group  lp_date  \\\n",
       "0        0     ...           0.0     Wave2       ab-         NaN      NaN   \n",
       "1        0     ...           0.0  Baseline       ab-          T-      NaN   \n",
       "2        0     ...           1.0  Baseline       ab-          T-      NaN   \n",
       "3        0     ...           NaN  Baseline       ab+          T+      NaN   \n",
       "4        0     ...           NaN  Baseline       ab-          T+      NaN   \n",
       "\n",
       "   intake_date_w1  cni_w1_date  lp_w1_date  intake_date_w2  lp_w2_date  \n",
       "0      2014-10-16   2014-08-22  2014-10-09      2018-12-10  2019-03-05  \n",
       "1      2014-10-09   2015-02-19  2014-10-09      2018-10-24  2019-01-23  \n",
       "2      2015-02-17   2015-02-17  2014-11-13      2019-02-12  2019-02-13  \n",
       "3      2014-07-08   2014-08-20  2014-07-08             NaN         NaN  \n",
       "4      2014-09-29   2014-11-24  2014-09-18             NaN         NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_data_summ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check folders with errors and manually enter which scans they are\n",
    "\n",
    "avail_data_summ.loc[(avail_data_summ['pidn']==562), 'w1_fse'] = 1\n",
    "avail_data_summ.loc[(avail_data_summ['pidn']==598), 'w1_fse'] = 1\n",
    "avail_data_summ.loc[(avail_data_summ['pidn']==600), 'w1_cube'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "21\n",
      "42\n",
      "8\n",
      "38\n",
      "4\n",
      "17\n",
      "8\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "## count the wave 2 data that we have. From the date this is run,\n",
    "# all wave 2 data will be within two years so we don't need to worry about that\n",
    "w2_blood_np = len(avail_data_summ[avail_data_summ['w2_blood'] == 1])\n",
    "w2_blood_apos = len(avail_data_summ[(avail_data_summ['w2_blood'] == 1) & (avail_data_summ['ab_group'] == 'ab+')])\n",
    "w2_blood_aneg = len(avail_data_summ[(avail_data_summ['w2_blood'] == 1) & (avail_data_summ['ab_group'] == 'ab-')])\n",
    "\n",
    "w2_csf = len(avail_data_summ[avail_data_summ['w2_csf'] == 1])\n",
    "w2_csf_apos = len(avail_data_summ[(avail_data_summ['w2_csf'] == 1) & (avail_data_summ['ab_group'] == 'ab+')])\n",
    "w2_csf_aneg = len(avail_data_summ[(avail_data_summ['w2_csf'] == 1) & (avail_data_summ['ab_group'] == 'ab-')])\n",
    "\n",
    "w2_7t = len(avail_data_summ[avail_data_summ['w2_7T'] == 1])\n",
    "w2_7t_apos = len(avail_data_summ[(avail_data_summ['w2_7T'] == 1) & (avail_data_summ['ab_group'] == 'ab+')])\n",
    "w2_7t_aneg = len(avail_data_summ[(avail_data_summ['w2_7T'] == 1) & (avail_data_summ['ab_group'] == 'ab-')])\n",
    "\n",
    "print(w2_blood_np)\n",
    "print(w2_csf)\n",
    "print(w2_7t)\n",
    "\n",
    "print(w2_blood_apos)\n",
    "print(w2_blood_aneg)\n",
    "print(w2_csf_apos)\n",
    "print(w2_csf_aneg)\n",
    "print(w2_7t_apos)\n",
    "print(w2_7t_aneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "42\n",
      "31\n",
      "14\n",
      "41\n",
      "38\n",
      "40\n",
      "26\n",
      "/n\n",
      "8\n",
      "34\n",
      "8\n",
      "33\n",
      "5\n",
      "26\n",
      "3\n",
      "10\n",
      "7\n",
      "33\n",
      "7\n",
      "30\n",
      "6\n",
      "33\n",
      "5\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "## calculate the number of each w2 scan \n",
    "##this almost works, but need to iterate and repeat for each scan type\n",
    "\n",
    "num_w2_fse = sum(1 for x in (range(len(avail_data_summ.index))) if((avail_data_summ.loc[x, 'fse_ses1'] == 1) or (avail_data_summ.loc[x, 'fse_ses2'] == 1) or (avail_data_summ.loc[x, 'ufse_ses1'] == 1) or (avail_data_summ.loc[x, 'ufse_ses2'] == 1)))\n",
    "w2_fse_apos = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'fse_ses1'] == 1) or (avail_data_summ.loc[x, 'fse_ses2'] == 1) or (avail_data_summ.loc[x, 'ufse_ses1'] == 1) or (avail_data_summ.loc[x, 'ufse_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_fse_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'fse_ses1'] == 1) or (avail_data_summ.loc[x, 'fse_ses2'] == 1) or (avail_data_summ.loc[x, 'ufse_ses1'] == 1) or (avail_data_summ.loc[x, 'ufse_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "  \n",
    "\n",
    "num_w2_wmn = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'wmn_ses1'] == 1) or (avail_data_summ.loc[x, 'wmn_ses2'] == 1)))\n",
    "w2_wmn_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'wmn_ses1'] == 1) or (avail_data_summ.loc[x, 'wmn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_wmn_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'wmn_ses1'] == 1) or (avail_data_summ.loc[x, 'wmn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "\n",
    "num_w2_mtrage = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'mtrage_ses1'] == 1) or (avail_data_summ.loc[x, 'mtrage_ses2'] == 1)))\n",
    "w2_mt_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'mtrage_ses1'] == 1) or (avail_data_summ.loc[x, 'mtrage_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_mt_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'mtrage_ses1'] == 1) or (avail_data_summ.loc[x, 'mtrage_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w2_flair = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'flair_ses1'] == 1) or (avail_data_summ.loc[x, 'flair_ses2'] == 1)))\n",
    "w2_flair_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'flair_ses1'] == 1) or (avail_data_summ.loc[x, 'flair_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_flair_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'flair_ses1'] == 1) or (avail_data_summ.loc[x, 'flair_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w2_csfn = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'csfn_ses1'] == 1) or (avail_data_summ.loc[x, 'csfn_ses2'] == 1)))\n",
    "w2_csfn_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'csfn_ses1'] == 1) or (avail_data_summ.loc[x, 'csfn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_csfn_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'csfn_ses1'] == 1) or (avail_data_summ.loc[x, 'csfn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w2_mepi = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'mepi_ses1'] == 1) or (avail_data_summ.loc[x, 'mepi_ses2'] == 1)))\n",
    "w2_mepi_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'mepi_ses1'] == 1) or (avail_data_summ.loc[x, 'mepi_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_mepi_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'mepi_ses1'] == 1) or (avail_data_summ.loc[x, 'mepi_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w2_gmn = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'gmn_ses1'] == 1) or (avail_data_summ.loc[x, 'gmn_ses2'] == 1)))\n",
    "w2_gmn_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'gmn_ses1'] == 1) or (avail_data_summ.loc[x, 'gmn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_gmn_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'gmn_ses1'] == 1) or (avail_data_summ.loc[x, 'gmn_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w2_qti = sum(1 for x in (range(len(avail_data_summ.index))) if ((avail_data_summ.loc[x, 'qti_ses1'] == 1) or (avail_data_summ.loc[x, 'qti_ses2'] == 1)))\n",
    "w2_qti_apos = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'qti_ses1'] == 1) or (avail_data_summ.loc[x, 'qti_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w2_qti_aneg = sum(1 for x in (range(len(avail_data_summ.index))) if (((avail_data_summ.loc[x, 'qti_ses1'] == 1) or (avail_data_summ.loc[x, 'qti_ses2'] == 1)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "\n",
    "print(num_w2_fse)\n",
    "print(num_w2_wmn)\n",
    "print(num_w2_mtrage)\n",
    "print(num_w2_flair)\n",
    "print(num_w2_csfn)\n",
    "print(num_w2_mepi)\n",
    "print(num_w2_gmn)\n",
    "print(num_w2_qti)\n",
    "print('/n') \n",
    "print(w2_fse_apos)\n",
    "print(w2_fse_aneg)\n",
    "print(w2_wmn_apos)\n",
    "print(w2_wmn_aneg)\n",
    "print(w2_mt_apos)\n",
    "print(w2_mt_aneg)\n",
    "print(w2_flair_apos)\n",
    "print(w2_flair_aneg) \n",
    "print(w2_csfn_apos)\n",
    "print(w2_csfn_aneg)\n",
    "print(w2_mepi_apos)\n",
    "print(w2_mepi_aneg)\n",
    "print(w2_gmn_apos)\n",
    "print(w2_gmn_aneg)\n",
    "print(w2_qti_apos)\n",
    "print(w2_qti_aneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "12\n",
      "4\n",
      "3\n",
      "9\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "8\n",
      "3\n",
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "## for those who have a W2 7T, which W1 scans do they also have?\n",
    "\n",
    "pidn1 = set(avail_data_summ[(avail_data_summ['fse_ses1'] == 1)]['pidn'])\n",
    "pidn2 = set(avail_data_summ[(avail_data_summ['ufse_ses1'] == 1)]['pidn'])\n",
    "pidn3 = set(avail_data_summ[(avail_data_summ['fse_ses2'] == 1)]['pidn'])\n",
    "pidn4 = set(avail_data_summ[(avail_data_summ['ufse_ses2'] == 1)]['pidn'])\n",
    "\n",
    "temp = list(pidn2-pidn1)\n",
    "temp2 = list(pidn3-pidn1)\n",
    "temp3 = list(pidn4-pidn1)\n",
    "\n",
    "pidn_to_check = list(pidn1) + temp+temp2+temp3\n",
    "print(len(pidn_to_check))\n",
    "\n",
    "num_w1_fse = sum(1 for x in (range(len(avail_data_summ.index))) if((avail_data_summ.loc[x, 'w1_fse'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)))\n",
    "w1_fse_pos = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_fse'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w1_fse_neg = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_fse'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w1_wmn = sum(1 for x in (range(len(avail_data_summ.index))) if((avail_data_summ.loc[x, 'w1_wmnmprage'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)))\n",
    "w1_wmn_pos = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_wmnmprage'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w1_wmn_neg = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_wmnmprage'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w1_flair = sum(1 for x in (range(len(avail_data_summ.index))) if((avail_data_summ.loc[x, 'w1_flair'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)))\n",
    "w1_flair_pos = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_flair'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w1_flair_neg = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_flair'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "num_w1_cube = sum(1 for x in (range(len(avail_data_summ.index))) if((avail_data_summ.loc[x, 'w1_cube'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)))\n",
    "w1_cube_pos = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_cube'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab+')))\n",
    "w1_cube_neg = sum(1 for x in (range(len(avail_data_summ.index))) if(((avail_data_summ.loc[x, 'w1_cube'] == 1) and (avail_data_summ.loc[x, 'pidn'] in pidn_to_check)) and (avail_data_summ.loc[x, 'ab_group'] == 'ab-')))\n",
    "\n",
    "\n",
    "        \n",
    "print(num_w1_fse)   \n",
    "print(num_w1_wmn)\n",
    "print(num_w1_flair)\n",
    "print(num_w1_cube)\n",
    "print(w1_fse_pos)\n",
    "print(w1_wmn_pos)\n",
    "print(w1_flair_pos)\n",
    "print(w1_cube_pos)\n",
    "print(w1_fse_neg)\n",
    "print(w1_wmn_neg)\n",
    "print(w1_flair_neg)\n",
    "print(w1_cube_neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "12\n",
      "26\n",
      "11\n",
      "7\n",
      "4\n",
      "5\n",
      "9\n",
      "10\n",
      "5\n",
      "7\n",
      "15\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "## What W1 data was collected in the past two years\n",
    "w1_blood_np = 0\n",
    "w1_lp = 0\n",
    "w1_7t = 0\n",
    "w1_cni = 0\n",
    "\n",
    "pt = 0 \n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_blood'] == 1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today() - date1\n",
    "        if time_diff.days <= 730:\n",
    "            w1_blood_np +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_cni'] == 1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'cni_w1_date'])\n",
    "        time_diff = datetime.date.today() - date2\n",
    "        if time_diff.days <= 730:\n",
    "            w1_cni +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_csf'] == 1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            w1_lp +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "#         print(time_diff)\n",
    "        if time_diff.days <= 730:\n",
    "            w1_7t +=1\n",
    "            \n",
    "    pt+=1\n",
    "    \n",
    "    \n",
    "pt = 0 \n",
    "w1_np_apos = 0\n",
    "w1_cni_apos =0\n",
    "w1_lp_apos=0\n",
    "w1_7t_apos=0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_blood'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today() - date1\n",
    "        if time_diff.days <= 730:\n",
    "            w1_np_apos +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_cni'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'cni_w1_date'])\n",
    "        time_diff = datetime.date.today() - date2\n",
    "        if time_diff.days <= 730:\n",
    "            w1_cni_apos +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_csf'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            w1_lp_apos +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "#         print(time_diff)\n",
    "        if time_diff.days <= 730:\n",
    "            w1_7t_apos +=1\n",
    "            \n",
    "    pt+=1\n",
    "    \n",
    "pt = 0    \n",
    "w1_np_aneg = 0\n",
    "w1_cni_aneg =0\n",
    "w1_lp_aneg=0\n",
    "w1_7t_aneg=0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_blood'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today() - date1\n",
    "        if time_diff.days <= 730:\n",
    "            w1_np_aneg +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_cni'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'cni_w1_date'])\n",
    "        time_diff = datetime.date.today() - date2\n",
    "        if time_diff.days <= 730:\n",
    "            w1_cni_aneg +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_csf'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            w1_lp_aneg +=1\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "#         print(time_diff)\n",
    "        if time_diff.days <= 730:\n",
    "            w1_7t_aneg +=1\n",
    "            \n",
    "    pt+=1\n",
    "    \n",
    "print(w1_blood_np)\n",
    "print(w1_lp)\n",
    "print(w1_7t)\n",
    "print(w1_cni)\n",
    "\n",
    "print(w1_np_apos)\n",
    "print(w1_cni_apos)\n",
    "print(w1_lp_apos)\n",
    "print(w1_7t_apos)\n",
    "\n",
    "print(w1_np_aneg)\n",
    "print(w1_cni_aneg)\n",
    "print(w1_lp_aneg)\n",
    "print(w1_7t_aneg)\n",
    "\n",
    "print(len(pidn_to_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "24\n",
      "20\n",
      "1\n",
      "9\n",
      "8\n",
      "5\n",
      "1\n",
      "15\n",
      "14\n",
      "13\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "pt = 0\n",
    "\n",
    "fse = 0\n",
    "wmn = 0\n",
    "flair=0\n",
    "cube=0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            if avail_data_summ.loc[pt, 'w1_fse'] == 1:\n",
    "                fse +=1\n",
    "            elif avail_data_summ.loc[pt, 'w1_ufse'] == 1:\n",
    "                fse +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_wmnmprage'] == 1:\n",
    "                wmn+=1\n",
    "            if avail_data_summ.loc[pt, 'w1_flair'] == 1:\n",
    "                flair +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_cube'] ==1:\n",
    "                cube+=1\n",
    "\n",
    "    pt+=1\n",
    "    \n",
    "pt = 0\n",
    "\n",
    "fse_apos = 0\n",
    "wmn_apos = 0\n",
    "flair_apos=0\n",
    "cube_apos=0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            if avail_data_summ.loc[pt, 'w1_fse'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "                fse_apos +=1\n",
    "            elif avail_data_summ.loc[pt, 'w1_ufse'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "                fse_apos +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_wmnmprage'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "                wmn_apos+=1\n",
    "            if avail_data_summ.loc[pt, 'w1_flair'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "                flair_apos +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_cube'] ==1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab+':\n",
    "                cube_apos+=1\n",
    "\n",
    "    pt+=1\n",
    "    \n",
    "pt = 0\n",
    "\n",
    "fse_aneg = 0\n",
    "wmn_aneg = 0\n",
    "flair_aneg=0\n",
    "cube_aneg=0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    if avail_data_summ.loc[pt, 'w1_7t'] == 1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[pt, 'lp_w1_date'])\n",
    "        time_diff = datetime.date.today() - date3\n",
    "        if time_diff.days <= 730:\n",
    "            if avail_data_summ.loc[pt, 'w1_fse'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "                fse_aneg +=1\n",
    "            elif avail_data_summ.loc[pt, 'w1_ufse'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "                fse_aneg +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_wmnmprage'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "                wmn_aneg+=1\n",
    "            if avail_data_summ.loc[pt, 'w1_flair'] == 1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "                flair_aneg +=1\n",
    "            if avail_data_summ.loc[pt, 'w1_cube'] ==1 and avail_data_summ.loc[pt, 'ab_group'] == 'ab-':\n",
    "                cube_aneg+=1\n",
    "\n",
    "    pt+=1\n",
    "    \n",
    "print(fse)\n",
    "print(wmn)\n",
    "print(flair)\n",
    "print(cube)\n",
    "\n",
    "print(fse_apos)\n",
    "print(wmn_apos)\n",
    "print(flair_apos)\n",
    "print(cube_apos)\n",
    "\n",
    "print(fse_aneg)\n",
    "print(wmn_aneg)\n",
    "print(flair_aneg)\n",
    "print(cube_aneg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIDN</th>\n",
       "      <th>Scan</th>\n",
       "      <th>wave</th>\n",
       "      <th>ab_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203</td>\n",
       "      <td>Tau PET</td>\n",
       "      <td>Wave2</td>\n",
       "      <td>ab-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>Tau PET</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>Tau PET</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>Amyloid PET</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>ab-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>472</td>\n",
       "      <td>Amyloid PET</td>\n",
       "      <td>Wave2</td>\n",
       "      <td>ab-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIDN         Scan      wave ab_group\n",
       "0   203      Tau PET     Wave2      ab-\n",
       "1   301      Tau PET  Baseline      ab-\n",
       "2   303      Tau PET  Baseline      ab-\n",
       "3   457  Amyloid PET  Baseline      ab-\n",
       "4   472  Amyloid PET     Wave2      ab-"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_data = pd.DataFrame()\n",
    "curr_path = '/Users/madisonhunt/Desktop/SAMS_PET.csv'\n",
    "pet_data = pd.read_csv(curr_path)\n",
    "\n",
    "pet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_T_pos = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Baseline') and (pet_data.loc[x, 'ab_group'] == 'ab+') and (pet_data.loc[x, 'Scan'] == 'Tau PET')))\n",
    "base_T_neg = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Baseline') and (pet_data.loc[x, 'ab_group'] == 'ab-')and (pet_data.loc[x, 'Scan'] == 'Tau PET')))\n",
    "w2_T_pos = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Wave2') and (pet_data.loc[x, 'ab_group'] == 'ab+')and (pet_data.loc[x, 'Scan'] == 'Tau PET')))\n",
    "w2_T_neg = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Wave2') and (pet_data.loc[x, 'ab_group'] == 'ab-')and (pet_data.loc[x, 'Scan'] == 'Tau PET')))\n",
    "\n",
    "\n",
    "base_AB_pos = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Baseline') and (pet_data.loc[x, 'ab_group'] == 'ab+') and (pet_data.loc[x, 'Scan'] == 'Amyloid PET')))\n",
    "base_AB_neg = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Baseline') and (pet_data.loc[x, 'ab_group'] == 'ab-')and (pet_data.loc[x, 'Scan'] == 'Amyloid PET')))\n",
    "w2_AB_pos = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Wave2') and (pet_data.loc[x, 'ab_group'] == 'ab+')and (pet_data.loc[x, 'Scan'] == 'Amyloid PET')))\n",
    "w2_AB_neg = sum(1 for x in (range(len(pet_data.index))) if((pet_data.loc[x, 'wave'] == 'Wave2') and (pet_data.loc[x, 'ab_group'] == 'ab-')and (pet_data.loc[x, 'Scan'] == 'Amyloid PET')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "27\n",
      "1\n",
      "2\n",
      "4\n",
      "14\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(base_T_pos)\n",
    "print(base_T_neg)\n",
    "print(w2_T_pos)\n",
    "print(w2_T_neg)\n",
    "\n",
    "print(base_AB_pos)\n",
    "print(base_AB_neg)\n",
    "print(w2_AB_pos)\n",
    "print(w2_AB_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pidn  w2_blood  w2_csf  w2_7T  w1_blood  w1_csf  w1_cni  w1_7t  w1_fse  \\\n",
      "0     203       1.0     1.0    1.0         1       1     0.0      1       0   \n",
      "1     301       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "2     303       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "3     405       NaN     NaN    NaN         1       1     1.0      0       0   \n",
      "4     415       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "5     416       NaN     NaN    NaN         1       0     NaN      0       0   \n",
      "6     423       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "7     447       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "8     448       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "9     449       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "10    456       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "11    457       1.0     0.0    1.0         1       1     1.0      1       0   \n",
      "12    460       NaN     NaN    NaN         1       0     NaN      0       0   \n",
      "13    463       NaN     NaN    NaN         1       0     0.0      0       0   \n",
      "14    468       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "15    470       NaN     NaN    NaN         1       1     0.0      1       0   \n",
      "16    472       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "17    474       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "18    475       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "19    476       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "20    477       1.0     0.0    1.0         1       1     1.0      1       0   \n",
      "21    478       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "22    479       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "23    481       1.0     1.0    0.0         1       1     1.0      0       0   \n",
      "24    482       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "25    488       NaN     NaN    NaN         1       1     1.0      1       0   \n",
      "26    489       1.0     1.0    1.0         1       1     1.0      1       0   \n",
      "27    500       1.0     0.0    1.0         1       1     0.0      1       0   \n",
      "28    504       1.0     0.0    1.0         1       1     0.0      1       0   \n",
      "29    507       1.0     0.0    1.0         1       0     1.0      1       0   \n",
      "..    ...       ...     ...    ...       ...     ...     ...    ...     ...   \n",
      "187  1083       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "188  1094       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "189  1095       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "190  1097       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "191  1099       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "192  1101       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "193  1104       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "194  1116       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "195  1119       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "196  1128       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "197  1135       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "198  1136       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "199  1137       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "200  1138       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "201  1141       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "202  1142       NaN     NaN    NaN         1       0     1.0      1       1   \n",
      "203  1163       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "204  1183       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "205  1184       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "206  1185       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "207  1190       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "208  1192       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "209  1193       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "210  1195       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "211  1196       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "212  1201       NaN     NaN    NaN         1       1     1.0      1       1   \n",
      "213  1227       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "214  1230       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "215  1231       NaN     NaN    NaN         1       1     2.0      1       1   \n",
      "216  1234       NaN     NaN    NaN         1       0     2.0      1       1   \n",
      "\n",
      "     w1_ufse     ...      qti_ses2      wave  ab_group  ptau_group   lp_date  \\\n",
      "0          0     ...           0.0     Wave2       ab-         NaN       NaN   \n",
      "1          0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "2          0     ...           1.0  Baseline       ab-          T-       NaN   \n",
      "3          0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "4          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "5          0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "6          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "7          0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "8          0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "9          0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "10         0     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "11         0     ...           1.0  Baseline       ab-          T-   9/10/19   \n",
      "12         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "13         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "14         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "15         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "16         0     ...           0.0     Wave2       ab-         NaN   12/3/19   \n",
      "17         0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "18         0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "19         0     ...           0.0     Wave2       ab-         NaN   9/17/19   \n",
      "20         0     ...           1.0  Baseline       ab-          T-       NaN   \n",
      "21         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "22         0     ...           1.0  Baseline       ab+          T-       NaN   \n",
      "23         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "24         0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "25         0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "26         0     ...           0.0  Baseline       ab-          T-       NaN   \n",
      "27         0     ...           1.0  Baseline       ab-          T+  12/11/19   \n",
      "28         0     ...           1.0  Baseline       ab-          T-   7/31/19   \n",
      "29         0     ...           0.0     Wave2       ab-         NaN   7/10/19   \n",
      "..       ...     ...           ...       ...       ...         ...       ...   \n",
      "187        1     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "188        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "189        0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "190        1     ...           NaN  Baseline       ab-         NaN   8/28/19   \n",
      "191        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "192        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "193        0     ...           NaN  Baseline       ab-         NaN   10/3/19   \n",
      "194        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "195        0     ...           NaN  Baseline       ab-         NaN    9/4/19   \n",
      "196        0     ...           NaN  Baseline       ab+         NaN    9/3/19   \n",
      "197        0     ...           NaN  Baseline       ab-         NaN    9/4/19   \n",
      "198        0     ...           NaN  Baseline       ab-         NaN   10/8/19   \n",
      "199        0     ...           NaN  Baseline       ab-         NaN   10/1/19   \n",
      "200        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "201        1     ...           NaN  Baseline       ab+         NaN    9/4/19   \n",
      "202        0     ...           NaN       NaN       NaN         NaN       NaN   \n",
      "203        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "204        0     ...           NaN  Baseline       ab+         NaN   10/2/19   \n",
      "205        0     ...           NaN  Baseline       ab+         NaN   9/25/19   \n",
      "206        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "207        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "208        1     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "209        0     ...           NaN  Baseline       ab+          T-       NaN   \n",
      "210        0     ...           NaN  Baseline       ab-         NaN   1/23/20   \n",
      "211        0     ...           NaN  Baseline       ab-         NaN    2/5/20   \n",
      "212        0     ...           NaN  Baseline       ab+          T+       NaN   \n",
      "213        1     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "214        0     ...           NaN  Baseline       ab-          T-       NaN   \n",
      "215        1     ...           NaN  Baseline       ab-          T+       NaN   \n",
      "216        0     ...           NaN  Baseline       ab-         NaN  12/19/19   \n",
      "\n",
      "     intake_date_w1  cni_w1_date  lp_w1_date  intake_date_w2  lp_w2_date  \n",
      "0        2014-10-16   2014-08-22  2014-10-09      2018-12-10  2019-03-05  \n",
      "1        2014-10-09   2015-02-19  2014-10-09      2018-10-24  2019-01-23  \n",
      "2        2015-02-17   2015-02-17  2014-11-13      2019-02-12  2019-02-13  \n",
      "3        2014-07-08   2014-08-20  2014-07-08             NaN         NaN  \n",
      "4        2014-09-29   2014-11-24  2014-09-18             NaN         NaN  \n",
      "5        2014-08-26   2014-08-29         NaN             NaN         NaN  \n",
      "6        2014-09-23   2014-11-21  2014-11-18             NaN         NaN  \n",
      "7        2015-01-08          NaN  2015-01-13             NaN         NaN  \n",
      "8        2015-01-08   2015-01-08  2015-01-13             NaN         NaN  \n",
      "9        2014-12-10   2015-03-12  2015-03-05             NaN         NaN  \n",
      "10       2015-04-07   2015-04-02  2015-04-07             NaN         NaN  \n",
      "11       2015-03-17   2015-03-17  2015-03-23      2019-03-04  2019-03-18  \n",
      "12       2015-01-27          NaN         NaN             NaN         NaN  \n",
      "13       2015-02-10   2015-02-10         NaN             NaN         NaN  \n",
      "14       2015-03-10   2015-03-10  2015-03-18             NaN         NaN  \n",
      "15       2015-07-07   2015-07-07  2015-09-15             NaN         NaN  \n",
      "16       2015-03-24   2015-03-24  2015-04-06      2019-08-26  2019-10-22  \n",
      "17       2015-03-12   2015-03-12  2015-03-30             NaN         NaN  \n",
      "18       2015-02-24   2015-02-24  2015-03-04      2018-11-28  2019-03-06  \n",
      "19       2015-08-12   2015-08-12  2015-09-21      2019-08-12  2019-08-28  \n",
      "20       2016-02-16   2016-03-03  2016-04-11      2019-12-04         NaN  \n",
      "21       2015-09-30   2015-12-08  2015-10-14             NaN         NaN  \n",
      "22       2015-11-10   2015-12-01  2015-12-02      2019-05-16  2019-06-25  \n",
      "23       2015-03-11   2015-03-03  2015-03-24      2018-10-25  2019-01-15  \n",
      "24       2015-06-16   2015-06-16  2015-07-01             NaN         NaN  \n",
      "25       2015-02-12   2015-02-12  2015-02-18             NaN         NaN  \n",
      "26       2015-03-26   2015-03-26  2015-04-01      2018-11-01  2019-02-27  \n",
      "27       2015-10-13   2015-11-19  2015-12-16      2019-10-31         NaN  \n",
      "28       2015-04-16   2015-04-16  2015-05-06      2019-05-06  2019-05-07  \n",
      "29       2015-04-30   2015-04-30  2015-05-11      2019-02-26         NaN  \n",
      "..              ...          ...         ...             ...         ...  \n",
      "187      2018-08-21   2018-10-25  2018-12-04             NaN         NaN  \n",
      "188      2018-09-20   2018-11-19  2018-11-29             NaN         NaN  \n",
      "189      2018-10-04   2018-11-05  2018-12-05             NaN         NaN  \n",
      "190      2018-11-21   2019-01-31  2019-02-20             NaN         NaN  \n",
      "191      2018-10-22   2018-12-12  2019-01-29             NaN         NaN  \n",
      "192      2018-11-12   2019-01-21  2019-03-27             NaN         NaN  \n",
      "193      2018-10-18   2018-12-10  2018-12-11             NaN         NaN  \n",
      "194      2018-11-19   2018-12-18  2019-01-22             NaN         NaN  \n",
      "195      2019-02-19   2019-04-25  2019-04-03             NaN         NaN  \n",
      "196      2019-01-09   2019-02-11  2019-03-27             NaN         NaN  \n",
      "197      2019-01-14   2019-03-07  2019-03-20             NaN         NaN  \n",
      "198      2019-01-17   2019-02-26  2019-03-19             NaN         NaN  \n",
      "199      2019-02-11   2019-07-09  2019-04-09             NaN         NaN  \n",
      "200      2019-02-06   2019-04-30  2019-04-09             NaN         NaN  \n",
      "201      2019-02-04   2019-03-14  2019-03-20             NaN         NaN  \n",
      "202      2019-02-07   2019-03-28  2019-04-03             NaN         NaN  \n",
      "203      2019-03-07   2019-04-11  2019-07-02             NaN         NaN  \n",
      "204      2019-04-11   2019-06-11  2019-07-24             NaN         NaN  \n",
      "205      2019-04-16   2019-06-03  2019-07-23             NaN         NaN  \n",
      "206      2019-04-15   2019-05-09  2019-06-18             NaN         NaN  \n",
      "207      2019-06-06   2019-08-05  2019-10-10             NaN         NaN  \n",
      "208      2019-05-23   2019-08-01  2019-11-07             NaN         NaN  \n",
      "209      2019-05-20   2019-06-24  2019-09-18             NaN         NaN  \n",
      "210      2019-05-15   2019-08-12  2019-07-02             NaN         NaN  \n",
      "211      2019-07-30   2019-09-23  2019-10-15             NaN         NaN  \n",
      "212      2019-07-17   2019-09-30  2019-11-06             NaN         NaN  \n",
      "213      2019-09-10   2019-11-18  2020-01-30             NaN         NaN  \n",
      "214      2019-10-08   2019-11-04  2019-11-22             NaN         NaN  \n",
      "215      2019-09-09   2019-10-31  2020-01-23             NaN         NaN  \n",
      "216      2019-10-21   2019-12-09  2019-12-05             NaN         NaN  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[217 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(avail_data_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>intake_w1</th>\n",
       "      <th>cni</th>\n",
       "      <th>lp_w1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  intake_w1   cni  lp_w1\n",
       "0  24.0       19.0  11.0   25.0\n",
       "1  18.0        5.0   2.0   10.0\n",
       "2  30.0       32.0  19.0   38.0\n",
       "3  36.0       59.0  46.0   61.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_data = pd.DataFrame()\n",
    "x = 0\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 24\n",
    "    if avail_data_summ.loc[y, 'w1_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 730:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_cni'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'cni_w1_date'])\n",
    "        if (datetime.date.today()-date2).days < 730:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_7t'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w1_date'])\n",
    "        if (datetime.date.today()-date3).days < 730:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w1'] = temp1_count\n",
    "dates_data.loc[x, 'cni'] = temp2_count\n",
    "dates_data.loc[x, 'lp_w1'] = temp3_count\n",
    "    \n",
    "x = 1\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 18\n",
    "    if avail_data_summ.loc[y, 'w1_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 548:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_cni'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'cni_w1_date'])\n",
    "        if (datetime.date.today()-date2).days < 548:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_7t'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w1_date'])\n",
    "        if (datetime.date.today()-date3).days < 548:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w1'] = temp1_count\n",
    "dates_data.loc[x, 'cni'] = temp2_count\n",
    "dates_data.loc[x, 'lp_w1'] = temp3_count\n",
    "\n",
    "x = 2\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 30\n",
    "    if avail_data_summ.loc[y, 'w1_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 913:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_cni'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'cni_w1_date'])\n",
    "        if (datetime.date.today()-date2).days < 913:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_7t'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w1_date'])\n",
    "        if (datetime.date.today()-date3).days < 913:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w1'] = temp1_count\n",
    "dates_data.loc[x, 'cni'] = temp2_count\n",
    "dates_data.loc[x, 'lp_w1'] = temp3_count\n",
    "\n",
    "x = 3\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 36\n",
    "    if avail_data_summ.loc[y, 'w1_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w1'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 1095:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_cni'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'cni_w1_date'])\n",
    "        if (datetime.date.today()-date2).days < 1095:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w1_7t'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w1_date'])\n",
    "        if (datetime.date.today()-date3).days < 1095:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w1'] = temp1_count\n",
    "dates_data.loc[x, 'cni'] = temp2_count\n",
    "dates_data.loc[x, 'lp_w1'] = temp3_count\n",
    "    \n",
    "dates_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fromisoformat: argument must be str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-69177f3cc51b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mtemp1_count\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavail_data_summ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w2_7T'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdate2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromisoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavail_data_summ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lp_w2_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdate2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m730\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtemp2_count\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fromisoformat: argument must be str"
     ]
    }
   ],
   "source": [
    "dates_data = pd.DataFrame()\n",
    "x = 0\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 24\n",
    "    if avail_data_summ.loc[y, 'w2_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w2'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 730:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_7T'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date2).days < 730:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_csf'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date3).days < 730:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w2'] = temp1_count\n",
    "dates_data.loc[x, '7t'] = temp2_count\n",
    "dates_data.loc[x, 'w2_csf'] = temp3_count\n",
    "    \n",
    "x = 1\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 18\n",
    "    if avail_data_summ.loc[y, 'w2_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w2'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 548:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_7T'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date2).days < 548:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_csf'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date3).days < 548:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w2'] = temp1_count\n",
    "dates_data.loc[x, '7t'] = temp2_count\n",
    "dates_data.loc[x, 'w2_csf'] = temp3_count\n",
    "\n",
    "x = 2\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 30\n",
    "    if avail_data_summ.loc[y, 'w2_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w2'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 913:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_7T'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date2).days < 913:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_csf'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date3).days < 913:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w2'] = temp1_count\n",
    "dates_data.loc[x, '7t'] = temp2_count\n",
    "dates_data.loc[x, 'w2_csf'] = temp3_count\n",
    "\n",
    "x = 3\n",
    "y=0\n",
    "temp1_count = 0\n",
    "temp2_count=0\n",
    "temp3_count = 0\n",
    "for pid in avail_data_summ['pidn']:\n",
    "    dates_data.loc[x, 'time'] = 36\n",
    "    if avail_data_summ.loc[y, 'w2_blood'] ==1:\n",
    "        date1 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'intake_date_w2'])\n",
    "        time_diff = datetime.date.today()-date1\n",
    "        if time_diff.days <= 1095:\n",
    "            temp1_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_7T'] ==1:\n",
    "        date2 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date2).days < 1095:\n",
    "            temp2_count +=1\n",
    "    if avail_data_summ.loc[y, 'w2_csf'] ==1:\n",
    "        date3 = datetime.date.fromisoformat(avail_data_summ.loc[y, 'lp_w2_date'])\n",
    "        if (datetime.date.today()-date3).days < 1095:\n",
    "            temp3_count +=1\n",
    "    y+=1\n",
    "    \n",
    "dates_data.loc[x, 'intake_w2'] = temp1_count\n",
    "dates_data.loc[x, '7t'] = temp2_count\n",
    "dates_data.loc[x, 'w2_csf'] = temp3_count\n",
    "    \n",
    "dates_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
